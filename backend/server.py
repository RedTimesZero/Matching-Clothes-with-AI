import io
import requests
import torch
import torch.nn as nn
from torchvision import models, transforms
from fastapi import FastAPI, File, UploadFile, Form
from fastapi.middleware.cors import CORSMiddleware
from PIL import Image
import torch.nn.functional as F
import json
import os
import sys
import numpy as np
from skimage.metrics import structural_similarity as ssim

app = FastAPI()

# --- è¨­å®š CORS ---
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==========================================
# 1. å®šç¾©æ¨¡åž‹æž¶æ§‹ (é›™é ­é¾) - ResNet åˆ†é¡žå™¨
# ==========================================
class MultiHeadResNet(nn.Module):
    def __init__(self, num_cats, num_cols):
        super().__init__()
        self.backbone = models.resnet18(pretrained=False)
        num_features = self.backbone.fc.in_features
        self.backbone.fc = nn.Identity()
        self.fc_cat = nn.Linear(num_features, num_cats)
        self.fc_color = nn.Linear(num_features, num_cols)

    def forward(self, x):
        features = self.backbone(x)
        return self.fc_cat(features), self.fc_color(features)

# ==========================================
# 2. è³‡æºç®¡ç† (å»¶é²è¼‰å…¥)
# ==========================================

# å…¨åŸŸè®Šæ•¸ - ResNet åˆ†é¡žå™¨
classifier = None
CLASS_NAMES = None
COLOR_NAMES = None

# è£ç½®
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# åœ–ç‰‡åˆ†é¡žé è™•ç† (ResNet)
transform_classify = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# ==========================================
# 2.1 SSIM ç›¸ä¼¼åº¦è¨ˆç®—å‡½æ•¸
# ==========================================
def image_similarity_ssim(img1: Image.Image, img2: Image.Image) -> float:
    """
    ç”¨ SSIM è¨ˆç®—å…©å¼µåœ–ç‰‡çš„ç›¸ä¼¼åº¦ (0-100%)
    ç„¡éœ€ AI æ¨¡åž‹ï¼Œè¨˜æ†¶é«”ä½”ç”¨ <1MB
    
    Args:
        img1: PIL Image ç‰©ä»¶
        img2: PIL Image ç‰©ä»¶
    
    Returns:
        ç›¸ä¼¼åº¦åˆ†æ•¸ (0-100)
    """
    try:
        # èª¿æ•´æˆç›¸åŒå°ºå¯¸ (224x224ï¼Œèˆ‡åˆ†é¡žæ¨¡åž‹ä¸€è‡´)
        size = (224, 224)
        img1_resized = img1.resize(size)
        img2_resized = img2.resize(size)
        
        # è½‰æˆç°éšŽ
        img1_gray = img1_resized.convert('L')
        img2_gray = img2_resized.convert('L')
        
        # è½‰æˆ numpy array
        arr1 = np.array(img1_gray, dtype=np.float32)
        arr2 = np.array(img2_gray, dtype=np.float32)
        
        # è¨ˆç®— SSIM (-1 åˆ° 1 ä¹‹é–“ï¼Œé€šå¸¸ 0-1)
        score = ssim(arr1, arr2, data_range=255.0)
        
        # è½‰æˆ 0-100%
        similarity = max(0, min(100, score * 100))
        
        return similarity
    
    except Exception as e:
        print(f"âŒ SSIM è¨ˆç®—éŒ¯èª¤: {e}")
        return 0.0

def load_class_mappings():
    """è¼‰å…¥é¡žåˆ¥æ˜ å°„ JSON"""
    json_path = os.path.join(os.path.dirname(__file__), "class_mapping.json")
    if not os.path.exists(json_path):
        print(f"âŒ æ‰¾ä¸åˆ° class_mapping.json")
        return {}, {}
    
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    return data.get('cat_map', {}), data.get('color_map', {})

def get_classifier_model():
    """å»¶é²è¼‰å…¥ ResNet åˆ†é¡žæ¨¡åž‹"""
    global classifier, CLASS_NAMES, COLOR_NAMES
    
    if classifier is not None:
        return classifier, CLASS_NAMES, COLOR_NAMES

    print("âš¡ æ­£åœ¨åˆå§‹åŒ–åˆ†é¡žæ¨¡åž‹ (ResNet)...")
    
    c_map, co_map = load_class_mappings()
    c_map = {int(k): v for k, v in c_map.items()}
    co_map = {int(k): v for k, v in co_map.items()}
    
    CLASS_NAMES = [c_map[i] for i in sorted(c_map.keys())] if c_map else []
    COLOR_NAMES = [co_map[i] for i in sorted(co_map.keys())] if co_map else []
    
    num_cats = len(CLASS_NAMES) if CLASS_NAMES else 1
    num_cols = len(COLOR_NAMES) if COLOR_NAMES else 1
    
    model = MultiHeadResNet(num_cats, num_cols)
    
    pth_name = "Model_Weights.pth"
    if not os.path.exists(pth_name):
        pth_name = "model_weights.pth"
    
    if os.path.exists(pth_name):
        try:
            state_dict = torch.load(pth_name, map_location=device)
            model.load_state_dict(state_dict)
            model.to(device)
            model.eval()
            classifier = model
            print(f"âœ… åˆ†é¡žæ¨¡åž‹è¼‰å…¥æˆåŠŸ ({pth_name})")
        except Exception as e:
            print(f"âŒ æ¬Šé‡æª”è¼‰å…¥å¤±æ•—: {e}")
            classifier = None
    else:
        print("âŒ æ‰¾ä¸åˆ° Model_Weights.pth")
        classifier = None

    return classifier, CLASS_NAMES, COLOR_NAMES

# ==========================================
# 3. API æŽ¥å£
# ==========================================

@app.get("/")
def home():
    return {"message": "AI Backend is Running!"}

@app.post("/predict_type")
async def predict_type(file: UploadFile = File(...)):
    model, classes, colors = get_classifier_model()
    
    if model is None:
        return {"category": "unknown", "color": "unknown", "error": "Model failed to load"}

    try:
        image_data = await file.read()
        image = Image.open(io.BytesIO(image_data)).convert("RGB")
        
        img_tensor = transform_classify(image).unsqueeze(0).to(device)
        
        with torch.no_grad():
            cat_logits, col_logits = model(img_tensor)
            _, cat_idx = torch.max(cat_logits, 1)
            _, col_idx = torch.max(col_logits, 1)
            
            c_idx = cat_idx.item()
            co_idx = col_idx.item()
            
            pred_cat = classes[c_idx] if classes and c_idx < len(classes) else "unknown"
            pred_col = colors[co_idx] if colors and co_idx < len(colors) else "unknown"

        return {"category": pred_cat, "color": pred_col}
    except Exception as e:
        print(f"é æ¸¬éŒ¯èª¤: {e}")
        return {"category": "error", "color": "error"}

@app.post("/compare_url")
async def compare_url(file1: UploadFile = File(...), url2: str = Form(...)):
    print("\n" + "="*60)
    print("ðŸ“¸ æ”¶åˆ° /compare_url è«‹æ±‚")
    print(f"ðŸ”— url2: {url2[:80]}...")
    
    try:
        # è®€å–ä¸Šå‚³çš„ç¬¬ä¸€å¼µåœ–
        file1_data = await file1.read()
        print(f"âœ… file1 å¤§å°: {len(file1_data)} bytes")
        img1 = Image.open(io.BytesIO(file1_data)).convert("RGB")
        print(f"âœ… img1 å°ºå¯¸: {img1.size}")
        
        # ä¸‹è¼‰ç¬¬äºŒå¼µåœ–
        print(f"â¬‡ï¸ æ­£åœ¨ä¸‹è¼‰ url2...")
        r = requests.get(url2, timeout=12)
        r.raise_for_status()
        print(f"âœ… url2 ä¸‹è¼‰æˆåŠŸ: {len(r.content)} bytes")
        img2 = Image.open(io.BytesIO(r.content)).convert("RGB")
        print(f"âœ… img2 å°ºå¯¸: {img2.size}")

        # è¨ˆç®— SSIM ç›¸ä¼¼åº¦ï¼ˆç„¡éœ€ CLIP æ¨¡åž‹ï¼Œè¨˜æ†¶é«”ä½”ç”¨ <1MBï¼‰
        print("ðŸ¤– è¨ˆç®— SSIM ç›¸ä¼¼åº¦...")
        score = image_similarity_ssim(img1, img2)
        print(f"ðŸŽ¯ SSIM ç›¸ä¼¼åº¦: {score:.2f}%")
        print("="*60 + "\n")
        
        return {
            "similarity": round(score, 2),
            "message": "success"
        }

    except Exception as e:
        print(f"âŒ æ¯”å°éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        print("="*60 + "\n")
        return {"similarity": 0, "message": str(e)}